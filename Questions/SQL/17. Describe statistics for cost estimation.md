## 17. Describe statistics for cost estimation

When calculating which possible expressions are the most optimal, the DBMS uses both **equivalence rules** and **catalogued information** about the database to make a decision. The DBMS catalogues statistical information about the database itself to make these guesses; specifically the following:

**n­­r** – The number of tuples in the relation r.

**br** – The number of blocks/memory containing tuples of relation r.

**lr** – The size of a tuple of relation r in bytes.

**fr** – The blocking factor of relation r, which is the number of tuples of relation r that fit into one block.

**V(A,r)** – The number of distinct values appearing in the relation r for attribute A.

These statistics are usually updated by the DBMS during low load. Preferably it would be able to update it on every modification, but due to performance issues it’s restricted to low-load occasions where it can partition the processing power required for it without slowing down the rest of the system.

These catalogs also store information about indices, such as B+-tree indices and leaf pages in index paths. It is not always possible for the optimizer to make use of indexes to calculate evaluation plans, however.

DBMS systems also typically store **histograms** of the values stored in the database, plotting values into groupings in a histogram to analyze the frequency of certain value ranges in order to take this into account.

An important thing to take into consideration is that cost estimates are **not accurate**. The lowest estimated execution cost is not necessarily the **actual** most optimal evaluation plan, but statistical analysis shows that plans with the lowest estimates are usually either the **actual** most optimal, or at the very least close to the actual most optimal.

A lot of estimation is centered around the expected size of operations which produce records, such as **Selections** and **Joins.**

When calculating the estimated size of a **Selection** operation, the expression used is:

`nr/V(A,r)`

As mentioned above, **nr** is the number of tuples in the relation, and **V(A,r)** is the number of distinct values in the relation for the given attribute. So the estimated cost is the amount of tuples present in the relation we perform the selection on, divided by the amount of distinct values we could possibly get out of the query. If the DBMS has stored a **histogram** of the values on attribute A, the optimization can further specify the ranges wherein the search should take place.

**Join size estimation** is more costly, being that it involves the estimation of **lr** cost for the Cartesian products generated. If "R ∩ S = ∅", meaning the relations have no attributes in common, then;

`r ⋈ s = r x s`

meaning that the cost of a **natural join** is the same as the cost of a **Cartesian product.**

